{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Árvore de decisão: o aprendizado de máquina presente no computador de classificação de rochas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "toc": true
   },
   "source": [
    "<h1>Sumário da apresentação<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introdução\" data-toc-modified-id=\"Introdução-1\">Introdução</a></span></li><li><span><a href=\"#Metodologia\" data-toc-modified-id=\"Metodologia-2\">Metodologia</a></span></li><li><span><a href=\"#Importando-as-dependências-necessárias\" data-toc-modified-id=\"Importando-as-dependências-necessárias-3\">Importando as dependências necessárias</a></span></li><li><span><a href=\"#Criando-o-seu-dado-(Tabela-de-Frequências):\" data-toc-modified-id=\"Criando-o-seu-dado-(Tabela-de-Frequências):-4\">Criando o seu dado (Tabela de Frequências):</a></span></li><li><span><a href=\"#Transformando-o-seu-dado-em-um-objeto-do-pandas\" data-toc-modified-id=\"Transformando-o-seu-dado-em-um-objeto-do-pandas-5\">Transformando o seu dado em um objeto do pandas</a></span></li><li><span><a href=\"#Referências\" data-toc-modified-id=\"Referências-6\">Referências</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Introdução"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-08T00:15:30.503528Z",
     "start_time": "2020-10-08T00:15:30.356069Z"
    },
    "cell_style": "center",
    "lang": "en",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Árvores de decisão são metaheurísticas dentro do campo da inteligência artificial que têm sido amplamente utilizadas para construir modelos de classificação, pois esses modelos se assemelham muito ao raciocínio humano sendo fáceis de entender. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-08T00:15:30.503528Z",
     "start_time": "2020-10-08T00:15:30.356069Z"
    },
    "cell_style": "center",
    "lang": "en",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " * O algoritmo é estruturado como uma série modelos sequenciais, que combinam logicamenteum conjunto de testes simples, onde cada teste compara um atributo numérico com um valor limite ou um atributo nominal com um conjunto de valores possíveis \\cite{Kotsiantis2013}. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Metodologia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* O algoritmo de árvore de decisão \\cite{sklearn_api} é proposto para a solução de um problema de classificação de rochas simples do tipo binária\\cite{scikit-learn}.\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Classificação do tipo binária baseia-se em dois aspectos principais a entropia e o ganho de informação \\cite{Sayad2020}. O ganho de informação ou divergência \\textit{Kullback–Leibler} é a diferença das entropia nas iterações i e i+1. Onde \n",
    " \n",
    " $$ i = 0,1,2,3 ..., n \\ \\forall \\ n \\in \\mathbb{I} $$\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-08T00:55:36.133651Z",
     "start_time": "2020-10-08T00:55:36.125631Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* A entropia pode ser definida com base na tabela de frequências que carrega as informações do seu dado. Quando a tabela de frequencia possui dois atributos a entropia pode ser escrita como:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\\begin{equation}\n",
    "E(t,x) = \\sum_{c \\in x}  P(c)E(c)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Existe uma variação da árvore de decião que utiliza  a rega de bayes sendo conhecia como árvore de decisão bayesiana. \n",
    "O teorema de bayes e uma igualdade simples que afirma $prob(A \\ e \\ B) = prob(B \\ e\\  A)$ :\n",
    "\n",
    "\\begin{equation}\n",
    "P(B|A) = \\frac{prob(A|B) prob(B)}{prob(A)}\n",
    "\\end{equation}\n",
    "\n",
    "Onde\n",
    "\n",
    "\n",
    "* $prob(A)$ probabilidade total\n",
    "* $prob(B)$ é chamado de probabilidade a priori a qual será modificada pela experiência\n",
    "* $prob(A|B)$ é a verossimilança que determina a experiência\n",
    "* $prob(B|A)$ é a probabilidade posterior, ou o nível de crença após a realização do experimento\n",
    "\n",
    "Esse teorema é útil quando interpretado como uma regra para indução: os dados e o evento A são considerados como sucessores de B, o grau de crença anterior a realização do experimento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Importando as dependências necessárias "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-08T05:04:33.532608Z",
     "start_time": "2020-10-08T05:04:32.826883Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import pandas as pd\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Criando o seu dado (Tabela de Frequências):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-08T05:04:33.543082Z",
     "start_time": "2020-10-08T05:04:33.536283Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "features = [[140, 1], [130, 1],\n",
    "           [150, 0], [170, 0]]# diâmetro e gomos\n",
    "labels = [0, 0, 1, 1] # 0 é maçã e 1 é laranja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " ## Transformando o seu dado em um objeto do pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-08T05:04:33.630969Z",
     "start_time": "2020-10-08T05:04:33.545703Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   diâmetro  gomo  frutas\n",
      "0       140     1       0\n",
      "1       130     1       0\n",
      "2       150     0       1\n",
      "3       170     0       1\n"
     ]
    }
   ],
   "source": [
    "Tabela = {'diâmetro': [140, 130, 150, 170],\n",
    "          'gomo': [1, 1, 0 ,0 ],\n",
    "          'frutas': [0, 0, 1, 1]\n",
    "          }\n",
    "TF = pd.DataFrame(data=Tabela)\n",
    "print(TF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-08T05:04:33.743104Z",
     "start_time": "2020-10-08T05:04:33.635127Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# o classificador encontra padrões nos dados de treinamento\n",
    "clf = tree.DecisionTreeClassifier() # instância do classificador\n",
    "clf = clf.fit(features, labels) # fit encontra padrões nos dados\n",
    "\n",
    "# iremos utilizar para classificar uma nova fruta\n",
    "print(clf.predict([[90, 0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Referências\n",
    "\n",
    "* (<a id=\"cit-Kotsiantis2013\" href=\"#call-Kotsiantis2013\">Kotsiantis, 2013</a>) Kotsiantis S. B., ``_Decision trees: a recent overview_'', Artificial Intelligence Review, vol. 39, number 4, pp. 261--283, Apr 2013.  [online](https://doi.org/10.1007/s10462-011-9272-4)\n",
    "\n",
    "* (<a id=\"cit-sklearn_api\" href=\"#call-sklearn_api\">Buitinck, Louppe <em>et al.</em>, 2013</a>) L. Buitinck, G. Louppe, M. Blondel <em>et al.</em>, ``_API design for machine learning software: experiences from the scikit-learn project_'', ECML PKDD Workshop: Languages for Data Mining and Machine Learning,  2013.\n",
    "\n",
    "* (<a id=\"cit-scikit-learn\" href=\"#call-scikit-learn\">Pedregosa, Varoquaux <em>et al.</em>, 2011</a>) Pedregosa F., Varoquaux G., Gramfort A. <em>et al.</em>, ``_Scikit-learn: Machine Learning in Python_'', Journal of Machine Learning Research, vol. 12, number , pp. 2825--2830,  2011.\n",
    "\n",
    "* (<a id=\"cit-Sayad2020\" href=\"#call-Sayad2020\">Saed, 2020</a>) Dr. Saed, ``_An Introduction to Data Science: Decision Tree_'',  2020.  [online](https://www.saedsayad.com/data_mining_map.htm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "references.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "82px",
    "width": "446px"
   },
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Sumário da apresentação",
   "title_sidebar": "Conteúdo",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
